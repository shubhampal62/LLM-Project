{"cells":[{"cell_type":"markdown","metadata":{"id":"7G-elAowUyhP"},"source":["#Installing and Importing Libraries"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12088,"status":"ok","timestamp":1731138092753,"user":{"displayName":"Garv Makkar","userId":"09442862944139257927"},"user_tz":-330},"id":"hz7dEamY1fER","outputId":"e4af7b7a-177a-41aa-840f-69f6c273489b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["!pip install PyPDF2 sentence_transformers groq requests scikit-learn fuzzywuzzy streamlit python-docx docx2txt fpdf reportlab pyngrok -q\n","!python -m spacy download en_core_web_sm -q"]},{"cell_type":"markdown","metadata":{"id":"p95l4iDkeKyw"},"source":["# Mounting the Drive"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3096,"status":"ok","timestamp":1731138095844,"user":{"displayName":"Garv Makkar","userId":"09442862944139257927"},"user_tz":-330},"id":"2_4VAfh1-FBH","outputId":"41cc1a83-c705-4218-8776-d09a8ea9e8ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"kOJDgN6Cg0lx"},"source":["# Front End"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1731138601049,"user":{"displayName":"Garv Makkar","userId":"09442862944139257927"},"user_tz":-330},"id":"Y1zDCS9NkqCj","outputId":"9d6f001a-3d8c-4226-e088-d18a791bd176"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","\n","GROQ_API_KEY = \"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\"\n","\n","import streamlit as st\n","from io import BytesIO\n","import os\n","import json\n","import PyPDF2\n","import spacy\n","import random\n","import matplotlib.pyplot as plt\n","import re\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process\n","from tqdm import tqdm\n","from sentence_transformers import SentenceTransformer, util\n","from groq import Groq\n","from google.colab import drive\n","import nltk\n","from typing import List, Dict, Optional\n","from collections import deque\n","from PyPDF2 import PdfReader\n","from nltk.tokenize import sent_tokenize\n","nltk.download('punkt', quiet=True)\n","\n","JOB_ROLES = [\n","    \"Actuarial Analyst\",\n","    \"Computer Vision Engineer\",\n","    \"Data Analyst\",\n","    \"Data Engineer\",\n","    \"Data Scientist\",\n","    \"Financial Market Analyst\",\n","    \"Junior Analyst Developer\",\n","    \"MERN Developer\",\n","    \"Product Associate\",\n","    \"SDE_ SWE_ Software Development Engineer_ Software Engineer\"\n","]\n","\n","RAG_FOLDER_PATH = \"/content/drive/My Drive/LLM_RESUME_DATA/LLM Project Final/Mid Review 2/RAG folder - skills of particular roles/\"\n","\n","def extract_text_from_pdf(pdf_path):\n","    job_description = \"\"\n","    with open(pdf_path, 'rb') as pdf_file:\n","        pdf_reader = PyPDF2.PdfReader(pdf_file)\n","        for page in pdf_reader.pages:\n","            job_description += page.extract_text()\n","    return job_description\n","\n","def find_best_matching_role(sentence_model, job_description):\n","    job_description_embedding = sentence_model.encode(job_description, convert_to_tensor=True)\n","    job_roles_embeddings = sentence_model.encode(JOB_ROLES, convert_to_tensor=True)\n","    cosine_similarities = util.pytorch_cos_sim(job_description_embedding, job_roles_embeddings)\n","    best_match_index = cosine_similarities.argmax().item()\n","    return JOB_ROLES[best_match_index], cosine_similarities[0][best_match_index].item()\n","\n","def ask_question(question, modelname):\n","    client = Groq(api_key=GROQ_API_KEY)\n","    completion = client.chat.completions.create(\n","        model=modelname,\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are an expert in understanding and generating Job Descriptions and Resumes in CSE field.\"},\n","            {\"role\": \"user\", \"content\": question}\n","        ],\n","        temperature=0.5,\n","        max_tokens=1024,\n","        top_p=1,\n","        stream=True,\n","        stop=None,\n","    )\n","    response = \"\"\n","    for chunk in completion:\n","        response += chunk.choices[0].delta.content or \"\"\n","    return response\n","\n","def analyze_job_description(pdf_path, output_path, modelname):\n","    try:\n","        sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n","        nlp = spacy.load(\"en_core_web_sm\")\n","        job_description = extract_text_from_pdf(pdf_path)\n","        best_role, _ = find_best_matching_role(sentence_model, job_description)\n","        get_skills_prompt = f\"Here is a job description: {job_description}.\\n\\nUnderstand it and list all the required skills in a Python list format. Respond only with a Python list of skill names, and avoid any extra text or new lines.\"\n","        get_eligibility_prompt = f\"Here is a job description: {job_description}.\\n\\nUnderstand it and list all the required eligibility criteria in a Python list format. Respond only with a Python list of eligibility items, and avoid any extra text or new lines.\"\n","        skills = ask_question(get_skills_prompt, modelname)\n","        eligibility = ask_question(get_eligibility_prompt, modelname)\n","        result = {\n","            \"role\": best_role,\n","            \"skills\": skills,\n","            \"eligibility\": eligibility\n","        }\n","        with open(output_path, 'w') as json_file:\n","            json.dump(result, json_file, indent=4)\n","        return result\n","    except Exception as e:\n","        import traceback\n","        traceback.print_exc()\n","        return None\n","\n","def analyze_resume(pdf_path, output_path, modelname):\n","    try:\n","        resume_text = extract_text_from_pdf(pdf_path)\n","        person_details_prompt = (\n","            f\"Extract the person's details (name, phone, email, location) from this resume text: {resume_text}. \"\n","            \"Return the details strictly as a Python dictionary with keys 'name', 'phone', 'email', and 'location', and provide no extra text.\"\n","        )\n","        education_prompt = (\n","            f\"Extract the education details (degree, university, dates) from this resume text: {resume_text}. \"\n","            \"Return the information strictly as a list of dictionaries, where each dictionary contains 'degree', 'university', and 'dates'. Provide no extra text.\"\n","        )\n","        skills_prompt = (\n","            f\"Extract the skills from this resume text: {resume_text}. \"\n","            \"Return the skills strictly as a Python list of skill names, and provide no extra text.\"\n","        )\n","        work_ex_prompt = (\n","            f\"Extract the work experience (company, role, dates, responsibilities) from this resume text: {resume_text}. \"\n","            \"Return the information strictly as a list of dictionaries, with each dictionary containing 'company', 'role', 'dates', and 'responsibilities'. Provide no extra text.\"\n","        )\n","        projects_prompt = (\n","            f\"Extract the projects (name, description, technologies used) from this resume text: {resume_text}. \"\n","            \"Return each project strictly as a dictionary with 'name', 'description', and 'technologies_used' keys, and return all projects in a list format. Provide no extra text.\"\n","        )\n","        extras_prompt = (\n","            f\"Extract any additional information (awards, certifications, volunteer experience) from this resume text: {resume_text}. \"\n","            \"Return the information strictly as a list of dictionaries with each dictionary containing 'type' and 'details' for each extra item. Provide no extra text.\"\n","        )\n","        person_details = ask_question(person_details_prompt, modelname)\n","        education = ask_question(education_prompt, modelname)\n","        skills = ask_question(skills_prompt, modelname)\n","        work_ex = ask_question(work_ex_prompt, modelname)\n","        projects = ask_question(projects_prompt, modelname)\n","        extras = ask_question(extras_prompt, modelname)\n","        result = {\n","            \"person_details\": person_details,\n","            \"education\": education,\n","            \"skills\": skills,\n","            \"work_ex\": work_ex,\n","            \"projects\": projects,\n","            \"extras\": extras\n","        }\n","        with open(output_path, 'w') as json_file:\n","            json.dump(result, json_file, indent=4)\n","        return result\n","    except Exception as e:\n","        print(f\"Error processing file: {str(e)}\")\n","        return None\n","\n","def enhance_resume(jd_json_path, resume_json_path, output_path, modelname):\n","    try:\n","        with open(jd_json_path, 'r') as f:\n","            jd_data = json.load(f)\n","        with open(resume_json_path, 'r') as f:\n","            resume_data = json.load(f)\n","\n","        skills = resume_data.get('skills', {})\n","        work_ex = resume_data.get('work_ex', {})\n","        projects = resume_data.get('projects', {})\n","        extras = resume_data.get('extras', {})\n","\n","        skills_prompt = f\"\"\"\n","        Original skills section: {skills}\n","        Job description: {jd_data}\n","\n","        Please enhance the skills section by:\n","        1. Aligning it with the job description\n","        2. Using industry-standard terminology and formatting\n","        3. Prioritizing the most relevant skills first\n","\n","        Enhanced skills section (maintain the original format):\n","        \"\"\"\n","\n","        work_ex_prompt = f\"\"\"\n","        Original work experience: {work_ex}\n","        Job description requirements: {jd_data}\n","\n","        Please enhance the work experience section by:\n","        1. Highlighting experiences that match the job requirements\n","        2. Using industry-standard terminology\n","        3. Quantifying achievements where possible\n","        4. Focusing on relevant responsibilities\n","\n","        Enhanced work experience section (maintain the original format):\n","        \"\"\"\n","\n","        projects_prompt = f\"\"\"\n","        Original projects section: {projects}\n","        Job description requirements: {jd_data}\n","\n","        Please enhance the projects section by:\n","        1. Highlighting projects that demonstrate required skills\n","        2. Using industry-standard technical terminology\n","        3. Emphasizing problem-solving and results\n","        4. Including relevant technical details\n","\n","        Enhanced projects section (maintain the original format):\n","        \"\"\"\n","\n","        extras_prompt = f\"\"\"\n","        Original extras section: {extras}\n","        Job requirements: {jd_data}\n","\n","        Please enhance the extras section by:\n","        1. Highlighting relevant certifications and achievements\n","        2. Including industry-specific accomplishments\n","        3. Adding relevant professional memberships or activities\n","        4. Removing less relevant information\n","\n","        Enhanced extras section (maintain the original format):\n","        \"\"\"\n","\n","        enhanced_skills = ask_question(skills_prompt, modelname)\n","        enhanced_work_ex = ask_question(work_ex_prompt, modelname)\n","        enhanced_projects = ask_question(projects_prompt, modelname)\n","        enhanced_extras = ask_question(extras_prompt, modelname)\n","\n","        enhanced_resume = {\n","            \"person_details\": resume_data.get('person_details', {}),\n","            \"education\": resume_data.get('education', {}),\n","            \"skills\": enhanced_skills,\n","            \"work_ex\": enhanced_work_ex,\n","            \"projects\": enhanced_projects,\n","            \"extras\": enhanced_extras\n","        }\n","\n","        with open(output_path, 'w') as f:\n","            json.dump(enhanced_resume, f, indent=4)\n","\n","        return enhanced_resume\n","\n","    except FileNotFoundError as e:\n","        print(f\"Error: Could not find input file - {str(e)}\")\n","        return None\n","    except json.JSONDecodeError as e:\n","        print(f\"Error: Invalid JSON format - {str(e)}\")\n","        return None\n","    except Exception as e:\n","        print(f\"Error enhancing resume: {str(e)}\")\n","        return None\n","\n","class RAGSystem:\n","    def __init__(self, api_key: str):\n","        self.api_key = api_key\n","        self.client = Groq(api_key=api_key)\n","        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n","        self.conversation_history = deque(maxlen=5)\n","\n","    def extract_text_from_pdf(self, pdf_path: str) -\u003e str:\n","        try:\n","            with open(pdf_path, 'rb') as file:\n","                reader = PdfReader(file)\n","                text = \"\"\n","                for page in reader.pages:\n","                    text += page.extract_text() + \" \"\n","            return text.strip()\n","        except Exception as e:\n","            print(f\"Error reading PDF {pdf_path}: {e}\")\n","            return \"\"\n","\n","    def create_chunks(self, text: str, chunk_size: int = 500) -\u003e List[str]:\n","        sentences = sent_tokenize(text)\n","        chunks = []\n","        current_chunk = \"\"\n","\n","        for sentence in sentences:\n","            if len(current_chunk) + len(sentence) \u003c chunk_size:\n","                current_chunk += \" \" + sentence\n","            else:\n","                if current_chunk:\n","                    chunks.append(current_chunk.strip())\n","                current_chunk = sentence\n","\n","        if current_chunk:\n","            chunks.append(current_chunk.strip())\n","\n","        return chunks\n","\n","    def get_embeddings(self, texts: List[str]):\n","        return self.embedding_model.encode(texts)\n","\n","    def find_relevant_chunks(self, query: str, chunks: List[str], top_k: int = 3) -\u003e List[str]:\n","        query_embedding = self.embedding_model.encode([query])\n","        chunk_embeddings = self.embedding_model.encode(chunks)\n","        similarities = chunk_embeddings @ query_embedding.T\n","        top_indices = similarities.argsort(axis=0)[-top_k:][::-1]\n","        return [chunks[idx[0]] for idx in top_indices]\n","\n","    def get_llm_response(self, query: str, context: str) -\u003e str:\n","        history_context = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in self.conversation_history])\n","\n","        prompt = f\"\"\"Based on the following context and conversation history, please answer the question.\n","        If the answer cannot be found in the context, say so clearly.\n","\n","        Context: {context}\n","\n","        Previous Conversation:\n","        {history_context}\n","\n","        Question: {query}\n","\n","        Answer:\"\"\"\n","\n","        try:\n","            completion = self.client.chat.completions.create(\n","                model=\"llama-3.1-70b-versatile\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are an expert in analyzing job descriptions and career-related documents.\"},\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                temperature=0.5,\n","                max_tokens=1024,\n","                stream=True\n","            )\n","\n","            response = \"\"\n","            for chunk in completion:\n","                if chunk.choices[0].delta.content:\n","                    response += chunk.choices[0].delta.content\n","\n","            return response.strip()\n","\n","        except Exception as e:\n","            print(f\"Error getting LLM response: {e}\")\n","            return \"I encountered an error while generating the response.\"\n","\n","    def update_conversation_history(self, query: str, answer: str):\n","        self.conversation_history.append((query, answer))\n","\n","    def process_query(self, folder_path: str, query: str) -\u003e Dict[str, any]:\n","        try:\n","            pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n","            if not pdf_files:\n","                return {\"answer\": \"No PDF files found in the specified folder.\", \"sources\": []}\n","            all_chunks = []\n","            sources_map = {}\n","\n","            for pdf_file in pdf_files:\n","                file_path = os.path.join(folder_path, pdf_file)\n","                text = self.extract_text_from_pdf(file_path)\n","                if text:\n","                    chunks = self.create_chunks(text)\n","                    all_chunks.extend(chunks)\n","                    for chunk in chunks:\n","                        sources_map[chunk] = pdf_file\n","\n","            if not all_chunks:\n","                return {\"answer\": \"No content could be extracted from the PDFs.\", \"sources\": []}\n","\n","            relevant_chunks = self.find_relevant_chunks(query, all_chunks)\n","            sources = [sources_map[chunk] for chunk in relevant_chunks]\n","            context = \"\\n\".join(relevant_chunks)\n","            answer = self.get_llm_response(query, context)\n","            self.update_conversation_history(query, answer)\n","\n","            return {\n","                \"answer\": answer,\n","                \"sources\": list(set(sources))\n","            }\n","\n","        except Exception as e:\n","            print(f\"Error in RAG pipeline: {e}\")\n","            return {\n","                \"answer\": \"An error occurred while processing your query.\",\n","                \"sources\": []\n","            }\n","\n","def enhance_resume_with_rag(jd_json_path: str, resume_json_path: str, output_path: str, rag_folder_path: str, modelname: str) -\u003e Dict:\n","    try:\n","        rag_system = RAGSystem(api_key=GROQ_API_KEY)\n","\n","        with open(jd_json_path, 'r') as f:\n","            jd_data = json.load(f)\n","        with open(resume_json_path, 'r') as f:\n","            resume_data = json.load(f)\n","\n","        role_query = f\"What are the key skills, responsibilities, and best practices for a {jd_data.get('role', '')} role?\"\n","        rag_knowledge = rag_system.process_query(rag_folder_path, role_query)\n","\n","        skills = resume_data.get('skills', {})\n","        work_ex = resume_data.get('work_ex', {})\n","        projects = resume_data.get('projects', {})\n","        extras = resume_data.get('extras', {})\n","\n","        skills_prompt = f\"\"\"\n","        Original skills section: {skills}\n","        Job description requirements: {jd_data}\n","        Industry knowledge from our database: {rag_knowledge['answer']}\n","\n","        Please enhance the skills section by:\n","        1. Aligning it with the job description\n","        2. Incorporating relevant industry-standard skills from our knowledge base\n","        3. Using proper terminology and formatting\n","        4. Prioritizing the most relevant skills first\n","\n","        Enhanced skills section (maintain the original format):\n","        \"\"\"\n","\n","        work_ex_prompt = f\"\"\"\n","        Original work experience: {work_ex}\n","        Job description requirements: {jd_data}\n","        Industry knowledge: {rag_knowledge['answer']}\n","\n","        Please enhance the work experience section by:\n","        1. Highlighting experiences that match the job requirements\n","        2. Using industry-standard terminology\n","        3. Quantifying achievements where possible\n","        4. Focusing on relevant responsibilities\n","\n","        Enhanced work experience section (maintain the original format):\n","        \"\"\"\n","\n","        projects_prompt = f\"\"\"\n","        Original projects section: {projects}\n","        Job description requirements: {jd_data}\n","        Industry knowledge: {rag_knowledge['answer']}\n","\n","        Please enhance the projects section by:\n","        1. Highlighting projects that demonstrate required skills\n","        2. Using industry-standard technical terminology\n","        3. Emphasizing problem-solving and results\n","        4. Including relevant technical details\n","\n","        Enhanced projects section (maintain the original format):\n","        \"\"\"\n","\n","        extras_prompt = f\"\"\"\n","        Original extras section: {extras}\n","        Job requirements: {jd_data}\n","        Industry knowledge: {rag_knowledge['answer']}\n","\n","        Please enhance the extras section by:\n","        1. Highlighting relevant certifications and achievements\n","        2. Including industry-specific accomplishments\n","        3. Adding relevant professional memberships or activities\n","        4. Removing less relevant information\n","\n","        Enhanced extras section (maintain the original format):\n","        \"\"\"\n","\n","        enhanced_skills = ask_question(skills_prompt, modelname)\n","        enhanced_work_ex = ask_question(work_ex_prompt, modelname)\n","        enhanced_projects = ask_question(projects_prompt, modelname)\n","        enhanced_extras = ask_question(extras_prompt, modelname)\n","\n","        enhanced_resume = {\n","            \"person_details\": resume_data.get('person_details', {}),\n","            \"education\": resume_data.get('education', {}),\n","            \"skills\": enhanced_skills,\n","            \"work_ex\": enhanced_work_ex,\n","            \"projects\": enhanced_projects,\n","            \"extras\": enhanced_extras,\n","            \"rag_sources\": rag_knowledge.get('sources', [])\n","        }\n","\n","        with open(output_path, 'w') as f:\n","            json.dump(enhanced_resume, f, indent=4)\n","\n","        return enhanced_resume\n","\n","    except FileNotFoundError as e:\n","        print(f\"Error: Could not find input file - {str(e)}\")\n","        return None\n","    except json.JSONDecodeError as e:\n","        print(f\"Error: Invalid JSON format - {str(e)}\")\n","        return None\n","    except Exception as e:\n","        print(f\"Error enhancing resume: {str(e)}\")\n","        return None\n","\n","def read_file(file):\n","    pdf_reader = PdfReader(file)\n","    text = []\n","    for page in pdf_reader.pages:\n","        page_text = page.extract_text()\n","        if page_text:\n","            text.extend(page_text.splitlines())\n","    return \"\\n\".join(text)\n","\n","def get_pdfs(file1, file2):\n","    resume_text = read_file(file1)\n","    jd_text = read_file(file2)\n","    resume_pdf = BytesIO(resume_text.encode(\"utf-8\"))\n","    jd_pdf = BytesIO(jd_text.encode(\"utf-8\"))\n","    return resume_pdf, jd_pdf\n","\n","def best_resume(jd_json_path, resume_json_path, enhanced_resume_path, best_model, best_version):\n","    if best_model == \"llama-3.1-70b-versatile\" and best_version == \"R1\":\n","        return enhance_resume(jd_json_path, resume_json_path, enhanced_resume_path, best_model)\n","    elif best_model == \"llama-3.1-70b-versatile\" and best_version == \"R2\":\n","        return enhance_resume_with_rag(jd_json_path, resume_json_path, enhanced_resume_path, RAG_FOLDER_PATH, best_model)\n","    elif best_model == \"llama-3.2-90b-text-preview\" and best_version == \"R1\":\n","        return enhance_resume(jd_json_path, resume_json_path, enhanced_resume_path, best_model)\n","    elif best_model == \"llama-3.2-90b-text-preview\" and best_version == \"R2\":\n","        return enhance_resume_with_rag(jd_json_path, resume_json_path, enhanced_resume_path, RAG_FOLDER_PATH, best_model)\n","    else:\n","        return resume_json_path\n","\n","def process_files(file1, file2, best_model, best_version):\n","    import tempfile\n","    import os\n","    from reportlab.pdfgen import canvas\n","    from reportlab.lib.pagesizes import letter\n","    from reportlab.pdfbase import pdfmetrics\n","    from reportlab.pdfbase.ttfonts import TTFont\n","    from reportlab.lib import colors\n","\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        try:\n","            log_file_path = os.path.join(temp_dir, \"processing_log.txt\")\n","            with open(log_file_path, \"w\") as log_file:\n","                log_file.write(\"Starting process...\\n\")\n","\n","            resume_pdf_path = os.path.join(temp_dir, \"resume.pdf\")\n","            jd_pdf_path = os.path.join(temp_dir, \"jd.pdf\")\n","            jd_json_path = os.path.join(temp_dir, \"jd.json\")\n","            resume_json_path = os.path.join(temp_dir, \"resume.json\")\n","            enhanced_resume_path = os.path.join(temp_dir, \"enhanced_resume.json\")\n","\n","            try:\n","                with open(resume_pdf_path, \"wb\") as f:\n","                    f.write(file1.getvalue())\n","                with open(jd_pdf_path, \"wb\") as f:\n","                    f.write(file2.getvalue())\n","\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(\"PDFs saved successfully.\\n\")\n","            except Exception as e:\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(f\"Error saving PDFs: {str(e)}\\n\")\n","                return None\n","\n","            try:\n","                jd = analyze_job_description(jd_pdf_path, jd_json_path, best_model)\n","                resume = analyze_resume(resume_pdf_path, resume_json_path, best_model)\n","\n","                if not jd or not resume:\n","                    with open(log_file_path, \"a\") as log_file:\n","                        log_file.write(\"Error analyzing documents.\\n\")\n","                    return None\n","\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(\"Documents analyzed successfully.\\n\")\n","            except Exception as e:\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(f\"Error during analysis: {str(e)}\\n\")\n","                return None\n","\n","            try:\n","                enhanced_data = best_resume(jd_json_path, resume_json_path, enhanced_resume_path, best_model, best_version)\n","                if not enhanced_data:\n","                    with open(log_file_path, \"a\") as log_file:\n","                        log_file.write(\"Error enhancing resume.\\n\")\n","                    return None\n","            except Exception as e:\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(f\"Error during enhancement: {str(e)}\\n\")\n","                return None\n","\n","            try:\n","                output = BytesIO()\n","                c = canvas.Canvas(output, pagesize=letter)\n","                width, height = letter\n","\n","                enhanced_text = json.dumps(enhanced_data, indent=2)\n","                lines = enhanced_text.split('\\n')\n","\n","                y = height - 50\n","                line_height = 12\n","                left_margin = 50\n","\n","                def new_page():\n","                    nonlocal y\n","                    c.showPage()\n","                    c.setFont(\"Helvetica\", 10)\n","                    y = height - 50\n","\n","                c.setFont(\"Helvetica\", 10)\n","\n","                for line in lines:\n","                    if y \u003c 50:\n","                        new_page()\n","\n","\n","                    while len(line) \u003e 100:\n","                        split_point = line[:100].rfind(' ')\n","                        if split_point == -1:\n","                            split_point = 100\n","\n","                        c.drawString(left_margin, y, line[:split_point])\n","                        line = line[split_point:].lstrip()\n","                        y -= line_height\n","\n","                        if y \u003c 50:\n","                            new_page()\n","\n","                    c.drawString(left_margin, y, line)\n","                    y -= line_height\n","\n","                c.save()\n","\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(\"Enhanced resume created successfully.\\n\")\n","\n","                output.seek(0)\n","                return output.getvalue()\n","\n","            except Exception as e:\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(f\"Error creating PDF: {str(e)}\\n\")\n","                return None\n","\n","        except Exception as e:\n","            try:\n","                with open(log_file_path, \"a\") as log_file:\n","                    log_file.write(f\"An error occurred: {str(e)}\\n\")\n","            except:\n","                pass\n","            return None\n","\n","best_model_and_r_path = \"/content/drive/My Drive/LLM_RESUME_DATA/LLM Project Final/Mid Review 2/best_model_and_r.txt\"\n","with open(best_model_and_r_path, \"r\") as f:\n","    lines = f.readlines()\n","    best_model = lines[0].strip()\n","    best_version = lines[1].strip()\n","\n","st.title(\"ResumeTune\")\n","file1 = st.file_uploader(\"Upload Resume\", type=[\"pdf\"])\n","file2 = st.file_uploader(\"Upload Job Description\", type=[\"pdf\"])\n","\n","if st.button(\"Enhance your Resume\"):\n","    if file1 is not None and file2 is not None:\n","        with st.spinner(\"Enhancing your resume... This may take a few minutes.\"):\n","            merged_pdf_data = process_files(file1, file2, best_model, best_version)\n","            if merged_pdf_data:\n","                st.success(\"Enhancement complete!\")\n","                st.download_button(\n","                    label=\"Download Enhanced Resume\",\n","                    data=merged_pdf_data,\n","                    file_name=\"enhanced_resume.pdf\",\n","                    mime=\"application/pdf\",\n","                )\n","            else:\n","                st.error(\"Failed to enhance resume. Please try again.\")\n","    else:\n","        st.error(\"Please upload both the resume and job description.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gDxofGY_rQaD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting Streamlit server...\n","Setting up ngrok tunnel...\n","\n","==================================================\n","Streamlit App URL: NgrokTunnel: \"https://1516-34-145-198-186.ngrok-free.app\" -\u003e \"http://localhost:8501\"\n","==================================================\n","\n"]}],"source":["from pyngrok import ngrok, conf\n","import os\n","import time\n","import subprocess\n","import signal\n","import psutil\n","\n","def kill_process_on_port(port):\n","    try:\n","        for proc in psutil.process_iter(['pid', 'name', 'connections']):\n","            try:\n","                for conn in proc.connections():\n","                    if conn.laddr.port == port:\n","                        os.kill(proc.pid, signal.SIGTERM)\n","                        time.sleep(1)\n","            except (psutil.NoSuchProcess, psutil.AccessDenied):\n","                continue\n","    except Exception as e:\n","        print(f\"Error killing process on port {port}: {e}\")\n","\n","def start_streamlit_server(port):\n","    try:\n","        kill_process_on_port(port)\n","\n","        os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'\n","        os.environ['STREAMLIT_SERVER_PORT'] = str(port)\n","\n","        process = subprocess.Popen(\n","            [\"streamlit\", \"run\", \"app.py\",\n","             \"--server.address\", \"0.0.0.0\",\n","             \"--server.port\", str(port)],\n","            stdout=subprocess.PIPE,\n","            stderr=subprocess.PIPE\n","        )\n","\n","        time.sleep(10)\n","        return process\n","    except Exception as e:\n","        print(f\"Error starting Streamlit: {e}\")\n","        return None\n","\n","def setup_ngrok(port, auth_token):\n","    try:\n","        # Configure ngrok\n","        conf.get_default().auth_token = auth_token\n","        conf.get_default().region = 'in'\n","\n","        # Kill any existing ngrok processes\n","        ngrok.kill()\n","\n","        # Start ngrok tunnel - simplified configuration\n","        public_url = ngrok.connect(port)\n","\n","        return public_url\n","    except Exception as e:\n","        print(f\"Error setting up ngrok: {e}\")\n","        return None\n","\n","def main():\n","    PORT = 8501\n","    AUTH_TOKEN = \"2oA2P8ECRxHzy0VQamBIrcr6w04_5nvMNVm9QnXijSFTaqxoq\"\n","\n","    try:\n","        print(\"Starting Streamlit server...\")\n","        streamlit_process = start_streamlit_server(PORT)\n","\n","        if not streamlit_process:\n","            raise Exception(\"Failed to start Streamlit server\")\n","\n","        print(\"Setting up ngrok tunnel...\")\n","        public_url = setup_ngrok(PORT, AUTH_TOKEN)\n","\n","        if not public_url:\n","            raise Exception(\"Failed to establish ngrok tunnel\")\n","\n","        print(\"\\n\" + \"=\"*50)\n","        print(f\"Streamlit App URL: {public_url}\")\n","        print(\"=\"*50 + \"\\n\")\n","\n","        try:\n","            while True:\n","                time.sleep(1)\n","        except KeyboardInterrupt:\n","            print(\"Shutting down...\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","    finally:\n","        print(\"Cleaning up...\")\n","        ngrok.kill()\n","        if 'streamlit_process' in locals():\n","            streamlit_process.terminate()\n","        kill_process_on_port(PORT)\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}